{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SD_Study Data Files Scanner and Analyzer\n",
    "In the drug registration process, SD files (short for Study Data files) refer to electronic data submissions that contain structured datasets from nonclinical and clinical studies. These datasets are prepared following standardized data models to allow regulatory agencies (like the FDA, EMA, or local authorities) to efficiently review, validate, and analyze the study results.\n",
    "\n",
    "### Definition\n",
    "**SD files** = Study Data Files — electronic data packages containing the raw and tabulated data from:\n",
    "**Nonclinical studies** (toxicology, pharmacology)\n",
    "**Clinical studies** (efficacy, safety, pharmacokinetics, etc.)\n",
    "\n",
    "### CDISC standards\n",
    "- SDTM (Study Data Tabulation Model) – standardized structure for tabulated data.\n",
    "- ADaM (Analysis Data Model) – datasets used for statistical analysis.\n",
    "- SEND (Standard for Exchange of Nonclinical Data) – for preclinical (animal) data.\n",
    "\n",
    "This notebook scans the current directory for files and analyzes specific file types using appropriate libraries:\n",
    "- **.sdf files**:  Structure Data File (Chemoinformatics) Plain text molecular data format used to store 3D structures, bonds, properties, and metadata - RDKit for chemical structure analysis\n",
    "- **.xpt files**: SAS XPORT (SDTM Clinical Datasets) Contains clinical study data such as Demographics (DM), Adverse Events (AE), and Laboratory Results (LB) - pyreadstat for SAS transport files\n",
    "- **.asnt files**: Textual representation of Abstract Syntax Notation One, sed in regulatory metadata, pharma labeling, and bioinformatics standards - Biopython for ASN.1 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if not already installed\n",
    "# Uncomment the following lines if you need to install packages\n",
    "\n",
    "!pip install -q rdkit-pypi\n",
    "!pip install -q pandas\n",
    "!pip install -q biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 files in the current directory and subdirectories\n",
      "\n",
      "Files by extension:\n",
      ".md: 2 files\n",
      "  - validation_README.md\n",
      "  - README.md\n",
      ": 59 files\n",
      "  - .DS_Store\n",
      "  - m5/.DS_Store\n",
      "  - m5/53-clin-stud-reports/.DS_Store\n",
      "  - m5/53-clin-stud-reports/study1234/.DS_Store\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/.DS_Store\n",
      "  ... and 54 more\n",
      ".csv: 6 files\n",
      "  - integrity_results.csv\n",
      "  - SD_Study-Data-files.csv\n",
      "  - validation_results.csv\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/dm.csv\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/ae.csv\n",
      "  ... and 1 more\n",
      ".ipynb: 2 files\n",
      "  - SD_Study-Data-files.ipynb\n",
      "  - SD_Study-Data-files_validated.ipynb\n",
      ".txt: 1 files\n",
      "  - validation_report.txt\n",
      ".pdf: 4 files\n",
      "  - SD_Study-Data-files.pdf\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/annotated-crf.pdf\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/study1234-clin-report.pdf\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/study1234-sdtm-rg.pdf\n",
      ".html: 1 files\n",
      "  - SD_Study-Data-files.html\n",
      ".py: 1 files\n",
      "  - run_validation.py\n",
      ".xlsx: 1 files\n",
      "  - sample_file_summary.xlsx\n",
      ".json: 1 files\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/COMPOUND_CID_197365.json\n",
      ".xml: 2 files\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/stf.xml\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/define.xml\n",
      ".xpt: 3 files\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/lb.xpt\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/ae.xpt\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/dm.xpt\n",
      ".asnt: 3 files\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/Conformer3D_COMPOUND_CID_197366.asnt\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/Structure2D_COMPOUND_CID_197365.asnt\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/assessment.asnt\n",
      ".sdf: 3 files\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/compound.sdf\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/Structure2D_COMPOUND_CID_197365.sdf\n",
      "  - m5/53-clin-stud-reports/study1234/datasets/datasets/Conformer3D_COMPOUND_CID_197366.sdf\n",
      ".sample: 14 files\n",
      "  - .git/hooks/commit-msg.sample\n",
      "  - .git/hooks/pre-rebase.sample\n",
      "  - .git/hooks/sendemail-validate.sample\n",
      "  - .git/hooks/pre-commit.sample\n",
      "  - .git/hooks/applypatch-msg.sample\n",
      "  ... and 9 more\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Scan current directory for files\n",
    "current_dir = Path('.')\n",
    "all_files = list(current_dir.rglob('*'))\n",
    "files_only = [f for f in all_files if f.is_file()]\n",
    "\n",
    "print(f\"Found {len(files_only)} files in the current directory and subdirectories\")\n",
    "\n",
    "# Group files by extension\n",
    "file_extensions = {}\n",
    "for file_path in files_only:\n",
    "    ext = file_path.suffix.lower()\n",
    "    if ext not in file_extensions:\n",
    "        file_extensions[ext] = []\n",
    "    file_extensions[ext].append(file_path)\n",
    "\n",
    "print(\"\\nFiles by extension:\")\n",
    "for ext, files in file_extensions.items():\n",
    "    print(f\"{ext}: {len(files)} files\")\n",
    "    for file in files[:5]:  # Show first 5 files per extension\n",
    "        print(f\"  - {file}\")\n",
    "    if len(files) > 5:\n",
    "        print(f\"  ... and {len(files) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation functions based on regulatory requirements\n",
    "import chardet\n",
    "import os\n",
    "\n",
    "def validate_xpt_file(file_path):\n",
    "    \"\"\"Validate XPT file according to regulatory requirements.\"\"\"\n",
    "    validation_results = {\n",
    "        'File': str(file_path.name),\n",
    "        'Format Check': 'PASS',\n",
    "        'CDISC Compliance': 'PASS',\n",
    "        'Required Variables': 'PASS',\n",
    "        'Data Integrity': 'PASS',\n",
    "        'Issues': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        import pyreadstat\n",
    "        df, meta = pyreadstat.read_xport(str(file_path))\n",
    "        \n",
    "        # Check format version\n",
    "        if meta.file_format != 'XPORT':\n",
    "            validation_results['Format Check'] = 'FAIL'\n",
    "            validation_results['Issues'].append(f'Not XPORT format: {meta.file_format}')\n",
    "        \n",
    "        # Check for required variables\n",
    "        required_vars = ['STUDYID', 'USUBJID']\n",
    "        missing_vars = [var for var in required_vars if var not in df.columns]\n",
    "        if missing_vars:\n",
    "            validation_results['Required Variables'] = 'FAIL'\n",
    "            validation_results['Issues'].append(f'Missing required variables: {missing_vars}')\n",
    "        \n",
    "        # Check for nulls in required fields\n",
    "        for var in required_vars:\n",
    "            if var in df.columns and df[var].isnull().any():\n",
    "                validation_results['Data Integrity'] = 'FAIL'\n",
    "                validation_results['Issues'].append(f'Null values in {var}')\n",
    "                break\n",
    "        \n",
    "        # Check for --SEQ if present\n",
    "        seq_cols = [col for col in df.columns if '--SEQ' in col.upper()]\n",
    "        for seq_col in seq_cols:\n",
    "            if df[seq_col].isnull().any():\n",
    "                validation_results['Data Integrity'] = 'FAIL'\n",
    "                validation_results['Issues'].append(f'Null values in {seq_col}')\n",
    "                break\n",
    "        \n",
    "    except Exception as e:\n",
    "        validation_results['Format Check'] = 'ERROR'\n",
    "        validation_results['Issues'].append(f'Error reading file: {str(e)}')\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def validate_sdf_file(file_path):\n",
    "    \"\"\"Validate SDF file according to regulatory requirements.\"\"\"\n",
    "    validation_results = {\n",
    "        'File': str(file_path.name),\n",
    "        'Structure Check': 'PASS',\n",
    "        'Molecule Count': 'PASS',\n",
    "        'Property Blocks': 'PASS',\n",
    "        'Connectivity': 'PASS',\n",
    "        'Issues': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        from rdkit import Chem\n",
    "        \n",
    "        with open(str(file_path), 'r') as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        # Check for proper SDF structure (molecules separated by $$$$)\n",
    "        molecules = content.split('$$$$')\n",
    "        molecules = [mol.strip() for mol in molecules if mol.strip()]\n",
    "        \n",
    "        if not molecules:\n",
    "            validation_results['Structure Check'] = 'FAIL'\n",
    "            validation_results['Issues'].append('No molecules found')\n",
    "            return validation_results\n",
    "        \n",
    "        # Validate each molecule\n",
    "        valid_molecules = 0\n",
    "        for i, mol_block in enumerate(molecules):\n",
    "            if not mol_block.strip():\n",
    "                continue\n",
    "            \n",
    "            # Try to parse with RDKit\n",
    "            mol = Chem.MolFromMolBlock(mol_block)\n",
    "            if mol is None:\n",
    "                validation_results['Connectivity'] = 'FAIL'\n",
    "                validation_results['Issues'].append(f'Molecule {i+1}: Invalid structure')\n",
    "            else:\n",
    "                valid_molecules += 1\n",
    "                \n",
    "                # Check atom/bond counts\n",
    "                if mol.GetNumAtoms() == 0:\n",
    "                    validation_results['Connectivity'] = 'FAIL'\n",
    "                    validation_results['Issues'].append(f'Molecule {i+1}: No atoms')\n",
    "                \n",
    "                # Check for property blocks\n",
    "                if '> ' not in mol_block:\n",
    "                    validation_results['Property Blocks'] = 'WARN'\n",
    "                    validation_results['Issues'].append(f'Molecule {i+1}: No property blocks found')\n",
    "        \n",
    "        if valid_molecules == 0:\n",
    "            validation_results['Molecule Count'] = 'FAIL'\n",
    "            validation_results['Issues'].append('No valid molecules')\n",
    "        \n",
    "    except Exception as e:\n",
    "        validation_results['Structure Check'] = 'ERROR'\n",
    "        validation_results['Issues'].append(f'Error reading file: {str(e)}')\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def validate_asnt_file(file_path):\n",
    "    \"\"\"Validate ASNT file according to regulatory requirements.\"\"\"\n",
    "    validation_results = {\n",
    "        'File': str(file_path.name),\n",
    "        'ASN.1 Structure': 'PASS',\n",
    "        'Encoding': 'PASS',\n",
    "        'Schema Compliance': 'PASS',\n",
    "        'Mandatory Fields': 'PASS',\n",
    "        'Issues': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check encoding\n",
    "        with open(str(file_path), 'rb') as f:\n",
    "            raw_data = f.read()\n",
    "        \n",
    "        detected_encoding = chardet.detect(raw_data)\n",
    "        encoding = detected_encoding.get('encoding', 'unknown')\n",
    "        \n",
    "        if encoding not in ['utf-8', 'ascii', 'UTF-8', 'ASCII']:\n",
    "            validation_results['Encoding'] = 'WARN'\n",
    "            validation_results['Issues'].append(f'Encoding {encoding} may not be compliant')\n",
    "        \n",
    "        # Try to decode\n",
    "        try:\n",
    "            content = raw_data.decode('utf-8')\n",
    "        except UnicodeDecodeError:\n",
    "            try:\n",
    "                content = raw_data.decode('ascii')\n",
    "            except UnicodeDecodeError:\n",
    "                validation_results['Encoding'] = 'FAIL'\n",
    "                validation_results['Issues'].append('Cannot decode file content')\n",
    "                return validation_results\n",
    "        \n",
    "        # Check if XML\n",
    "        if content.startswith('<?xml'):\n",
    "            import xml.etree.ElementTree as ET\n",
    "            try:\n",
    "                root = ET.fromstring(content)\n",
    "                validation_results['ASN.1 Structure'] = 'PASS (XML)'\n",
    "                \n",
    "                # Check for mandatory fields in assessment\n",
    "                mandatory_fields = ['StudyID', 'Reviewer', 'AssessmentDate']\n",
    "                missing_fields = []\n",
    "                for field in mandatory_fields:\n",
    "                    if not root.find(field) or not root.find(field).text:\n",
    "                        missing_fields.append(field)\n",
    "                \n",
    "                if missing_fields:\n",
    "                    validation_results['Mandatory Fields'] = 'FAIL'\n",
    "                    validation_results['Issues'].append(f'Missing mandatory fields: {missing_fields}')\n",
    "                \n",
    "            except ET.ParseError as e:\n",
    "                validation_results['Schema Compliance'] = 'FAIL'\n",
    "                validation_results['Issues'].append(f'Invalid XML: {str(e)}')\n",
    "        else:\n",
    "            # Assume ASN.1 text format\n",
    "            validation_results['ASN.1 Structure'] = 'PASS (Text)'\n",
    "            # Basic checks for ASN.1 structure\n",
    "            if '::=' not in content:\n",
    "                validation_results['Schema Compliance'] = 'WARN'\n",
    "                validation_results['Issues'].append('No ASN.1 definitions found')\n",
    "    \n",
    "    except Exception as e:\n",
    "        validation_results['ASN.1 Structure'] = 'ERROR'\n",
    "        validation_results['Issues'].append(f'Error reading file: {str(e)}')\n",
    "    \n",
    "    return validation_results\n",
    "\n",
    "def validate_file_integrity(file_path):\n",
    "    \"\"\"General file integrity checks.\"\"\"\n",
    "    integrity_results = {\n",
    "        'File': str(file_path.name),\n",
    "        'File Size': 'PASS',\n",
    "        'File Exists': 'PASS',\n",
    "        'Readable': 'PASS',\n",
    "        'Issues': []\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        # Check file exists\n",
    "        if not file_path.exists():\n",
    "            integrity_results['File Exists'] = 'FAIL'\n",
    "            integrity_results['Issues'].append('File does not exist')\n",
    "            return integrity_results\n",
    "        \n",
    "        # Check file size (FDA eCTD limit is typically 100MB per file)\n",
    "        size_mb = file_path.stat().st_size / (1024 * 1024)\n",
    "        if size_mb > 100:\n",
    "            integrity_results['File Size'] = 'WARN'\n",
    "            integrity_results['Issues'].append(f'File size {size_mb:.2f}MB exceeds typical limits')\n",
    "        \n",
    "        # Check readability\n",
    "        try:\n",
    "            with open(str(file_path), 'rb') as f:\n",
    "                f.read(1024)  # Read first 1KB\n",
    "        except Exception as e:\n",
    "            integrity_results['Readable'] = 'FAIL'\n",
    "            integrity_results['Issues'].append(f'File not readable: {str(e)}')\n",
    "    \n",
    "    except Exception as e:\n",
    "        integrity_results['Readable'] = 'ERROR'\n",
    "        integrity_results['Issues'].append(f'Error checking file: {str(e)}')\n",
    "    \n",
    "    return integrity_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SDF Files Analysis (RDKit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 SDF files\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/compound.sdf:\n",
      "  - Number of molecules: 0\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/Structure2D_COMPOUND_CID_197365.sdf:\n",
      "  - Number of molecules: 1\n",
      "  - First molecule: 197365\n",
      "  - Molecular weight: 699.99\n",
      "  - Number of atoms: 44\n",
      "  - Number of bonds: 46\n",
      "  - SMILES: CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl)cc6)[nH]c5c4)[nH]c3c2)CC1.Cl.Cl.Cl\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/Conformer3D_COMPOUND_CID_197366.sdf:\n",
      "  - Number of molecules: 1\n",
      "  - First molecule: 197366\n",
      "  - Molecular weight: 590.60\n",
      "  - Number of atoms: 41\n",
      "  - Number of bonds: 46\n",
      "  - SMILES: CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl)cc6)[nH]c5c4)[nH]c3c2)CC1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:20:08] ERROR: Atom line too short: '   -0.0015    1.2095    0.0000 C' on line 5\n",
      "[17:20:08] ERROR: moving to the beginning of the next molecule\n"
     ]
    }
   ],
   "source": [
    "# Analyze SDF files using RDKit\n",
    "try:\n",
    "    from rdkit import Chem\n",
    "    from rdkit.Chem import Descriptors\n",
    "    \n",
    "    sdf_files = file_extensions.get('.sdf', [])\n",
    "    if sdf_files:\n",
    "        print(f\"Found {len(sdf_files)} SDF files\")\n",
    "        \n",
    "        for sdf_file in sdf_files:\n",
    "            print(f\"\\nAnalyzing {sdf_file}:\")\n",
    "            \n",
    "            # Read SDF file\n",
    "            suppl = Chem.SDMolSupplier(str(sdf_file))\n",
    "            molecules = [mol for mol in suppl if mol is not None]\n",
    "            \n",
    "            print(f\"  - Number of molecules: {len(molecules)}\")\n",
    "            \n",
    "            if molecules:\n",
    "                # Analyze first molecule as example\n",
    "                mol = molecules[0]\n",
    "                print(f\"  - First molecule: {mol.GetProp('_Name') if mol.HasProp('_Name') else 'Unnamed'}\")\n",
    "                print(f\"  - Molecular weight: {Descriptors.MolWt(mol):.2f}\")\n",
    "                print(f\"  - Number of atoms: {mol.GetNumAtoms()}\")\n",
    "                print(f\"  - Number of bonds: {mol.GetNumBonds()}\")\n",
    "                print(f\"  - SMILES: {Chem.MolToSmiles(mol)}\")\n",
    "    else:\n",
    "        print(\"No SDF files found\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"RDKit not installed. Install with: pip install rdkit-pypi\")\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing SDF files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XPT Files Analysis (pyreadstat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 XPT files\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/lb.xpt:\n",
      "  - Shape: (2, 5)\n",
      "  - Columns: ['STUDYID', 'USUBJID', 'LBTEST', 'LBSTRESN', 'LBSTRESU']\n",
      "  - First 5 rows:\n",
      "  STUDYID  USUBJID      LBTEST  LBSTRESN LBSTRESU\n",
      "0  ABC123  SUBJ001  Hemoglobin      14.2     g/dL\n",
      "1  ABC123  SUBJ002     Glucose      88.0    mg/dL\n",
      "  - Summary statistics:\n",
      "       LBSTRESN\n",
      "count   2.00000\n",
      "mean   51.10000\n",
      "std    52.18448\n",
      "min    14.20000\n",
      "25%    32.65000\n",
      "50%    51.10000\n",
      "75%    69.55000\n",
      "max    88.00000\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/ae.xpt:\n",
      "  - Shape: (2, 5)\n",
      "  - Columns: ['STUDYID', 'USUBJID', 'AETERM', 'AESEV', 'AEREL']\n",
      "  - First 5 rows:\n",
      "  STUDYID  USUBJID    AETERM     AESEV      AEREL\n",
      "0  ABC123  SUBJ001  Headache      MILD    RELATED\n",
      "1  ABC123  SUBJ002    Nausea  MODERATE  UNRELATED\n",
      "  - Summary statistics:\n",
      "       STUDYID  USUBJID    AETERM AESEV    AEREL\n",
      "count        2        2         2     2        2\n",
      "unique       1        2         2     2        2\n",
      "top     ABC123  SUBJ001  Headache  MILD  RELATED\n",
      "freq         2        1         1     1        1\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/dm.xpt:\n",
      "  - Shape: (2, 4)\n",
      "  - Columns: ['STUDYID', 'USUBJID', 'AGE', 'SEX']\n",
      "  - First 5 rows:\n",
      "  STUDYID  USUBJID   AGE SEX\n",
      "0  ABC123  SUBJ001  45.0   M\n",
      "1  ABC123  SUBJ002  52.0   F\n",
      "  - Summary statistics:\n",
      "             AGE\n",
      "count   2.000000\n",
      "mean   48.500000\n",
      "std     4.949747\n",
      "min    45.000000\n",
      "25%    46.750000\n",
      "50%    48.500000\n",
      "75%    50.250000\n",
      "max    52.000000\n"
     ]
    }
   ],
   "source": [
    "# Analyze XPT files using pyreadstat\n",
    "try:\n",
    "    import pyreadstat\n",
    "    \n",
    "    xpt_files = file_extensions.get('.xpt', [])\n",
    "    if xpt_files:\n",
    "        print(f\"Found {len(xpt_files)} XPT files\")\n",
    "        \n",
    "        for xpt_file in xpt_files:\n",
    "            print(f\"\\nAnalyzing {xpt_file}:\")\n",
    "            \n",
    "            try:\n",
    "                # Read XPT file using pyreadstat\n",
    "                df, meta = pyreadstat.read_xport(str(xpt_file))\n",
    "                \n",
    "                print(f\"  - Shape: {df.shape}\")\n",
    "                print(f\"  - Columns: {list(df.columns)}\")\n",
    "                print(f\"  - First 5 rows:\\n{df.head()}\")\n",
    "                \n",
    "                # Basic statistics\n",
    "                print(f\"  - Summary statistics:\\n{df.describe()}\")\n",
    "                \n",
    "            except Exception as file_error:\n",
    "                print(f\"  - Error reading {xpt_file}: {file_error}\")\n",
    "                \n",
    "    else:\n",
    "        print(\"No XPT files found\")\n",
    "        \n",
    "except ImportError as e:\n",
    "    print(f\"Required packages not installed: {e}\")\n",
    "    print(\"Install with: pip install pyreadstat\")\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing XPT files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASNT Files Analysis (Biopython)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 ASNT files\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/Conformer3D_COMPOUND_CID_197366.asnt:\n",
      "  - Number of records: 0\n",
      "---\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/Structure2D_COMPOUND_CID_197365.asnt:\n",
      "  - Number of records: 0\n",
      "---\n",
      "\n",
      "Analyzing m5/53-clin-stud-reports/study1234/datasets/datasets/assessment.asnt:\n",
      "  - Number of records: 1\n",
      "  - XML Root: AssessmentTemplate\n",
      "    StudyID: STUDY1234\n",
      "    Reviewer: Dr. Smith\n",
      "    AssessmentDate: 2025-11-05\n",
      "    Findings: \n",
      "    \n",
      "    Recommendation: Approved for next review phase\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Analyze ASNT files using Biopython and XML parsing\n",
    "try:\n",
    "    from Bio import SeqIO\n",
    "    import xml.etree.ElementTree as ET\n",
    "    \n",
    "    def read_asnt(asnt_file):\n",
    "        # Check if it's XML\n",
    "        with open(asnt_file, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "            if first_line.startswith('<?xml'):\n",
    "                # It's XML, parse as XML\n",
    "                tree = ET.parse(asnt_file)\n",
    "                root = tree.getroot()\n",
    "                return [root]  # Return as list with one element\n",
    "            else:\n",
    "                # Try as ASN.1 sequence\n",
    "                records = list(SeqIO.parse(asnt_file, \"genbank\"))\n",
    "                return records\n",
    "    \n",
    "    asnt_files = file_extensions.get('.asnt', [])\n",
    "    if asnt_files:\n",
    "        print(f\"Found {len(asnt_files)} ASNT files\")\n",
    "        \n",
    "        for asnt_file in asnt_files:\n",
    "            print(f\"\\nAnalyzing {asnt_file}:\")\n",
    "            \n",
    "            try:\n",
    "                records = read_asnt(str(asnt_file))\n",
    "                print(f\"  - Number of records: {len(records)}\")\n",
    "                \n",
    "                for i, record in enumerate(records[:3]):  # Show first 3 records\n",
    "                    if hasattr(record, 'id'):  # BioPython record\n",
    "                        print(f\"  - Record {i+1}: {record.id}\")\n",
    "                        print(f\"    Description: {record.description}\")\n",
    "                        print(f\"    Sequence length: {len(record.seq)}\")\n",
    "                        print(f\"    Sequence type: {record.seq.alphabet}\")\n",
    "                    else:  # XML element\n",
    "                        print(f\"  - XML Root: {record.tag}\")\n",
    "                        for child in record:\n",
    "                            print(f\"    {child.tag}: {child.text}\")\n",
    "                print(\"---\")\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"  - Error reading {asnt_file}: {e}\")\n",
    "                # Fallback: read as text\n",
    "                try:\n",
    "                    with open(asnt_file, 'r') as f:\n",
    "                        content = f.read()\n",
    "                        print(f\"  - File size: {len(content)} characters\")\n",
    "                        print(f\"  - First 500 characters:\\n{content[:500]}...\")\n",
    "                except Exception as e2:\n",
    "                    print(f\"  - Error reading as text: {e2}\")\n",
    "    else:\n",
    "        print(\"No ASNT files found\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"Biopython not installed. Install with: pip install biopython\")\n",
    "except Exception as e:\n",
    "    print(f\"Error analyzing ASNT files: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANALYSIS SUMMARY ===\n",
      "Total files scanned: 103\n",
      "File extensions found: 15\n",
      ".SDF files: 3\n",
      ".XPT files: 3\n",
      ".ASNT files: 3\n",
      "\n",
      "Analysis complete!\n"
     ]
    }
   ],
   "source": [
    "# Summary of analysis\n",
    "print(\"=== ANALYSIS SUMMARY ===\")\n",
    "print(f\"Total files scanned: {len(files_only)}\")\n",
    "print(f\"File extensions found: {len(file_extensions)}\")\n",
    "\n",
    "# Check specific file types\n",
    "special_types = ['.sdf', '.xpt', '.asnt']\n",
    "for ext in special_types:\n",
    "    count = len(file_extensions.get(ext, []))\n",
    "    print(f\"{ext.upper()} files: {count}\")\n",
    "\n",
    "print(\"\\nAnalysis complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regulatory Validation Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== REGULATORY VALIDATION REPORT ===\n",
      "Report generated on: 2025-11-05 17:20:11\n",
      "Total files validated: 9\n",
      "\n",
      "Validation Summary:\n",
      "  PASS: 30\n",
      "  FAIL: 6\n",
      "  WARN: 0\n",
      "  ERROR: 0\n",
      "  Overall Compliance: REVIEW REQUIRED\n",
      "\n",
      "Detailed Validation Results:\n",
      "\n",
      "File: lb.xpt\n",
      "  Format Check: FAIL\n",
      "  CDISC Compliance: PASS\n",
      "  Required Variables: PASS\n",
      "  Data Integrity: PASS\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "  Issues: Not XPORT format: xport\n",
      "\n",
      "File: ae.xpt\n",
      "  Format Check: FAIL\n",
      "  CDISC Compliance: PASS\n",
      "  Required Variables: PASS\n",
      "  Data Integrity: PASS\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "  Issues: Not XPORT format: xport\n",
      "\n",
      "File: dm.xpt\n",
      "  Format Check: FAIL\n",
      "  CDISC Compliance: PASS\n",
      "  Required Variables: PASS\n",
      "  Data Integrity: PASS\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "  Issues: Not XPORT format: xport\n",
      "\n",
      "File: compound.sdf\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: PASS\n",
      "  Molecule Count: FAIL\n",
      "  Property Blocks: PASS\n",
      "  Connectivity: FAIL\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "  Issues: Molecule 1: Invalid structure, No valid molecules\n",
      "\n",
      "File: Structure2D_COMPOUND_CID_197365.sdf\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: PASS\n",
      "  Molecule Count: PASS\n",
      "  Property Blocks: PASS\n",
      "  Connectivity: PASS\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "\n",
      "File: Conformer3D_COMPOUND_CID_197366.sdf\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: PASS\n",
      "  Molecule Count: PASS\n",
      "  Property Blocks: PASS\n",
      "  Connectivity: PASS\n",
      "  ASN.1 Structure: nan\n",
      "  Encoding: nan\n",
      "  Schema Compliance: nan\n",
      "  Mandatory Fields: nan\n",
      "\n",
      "File: Conformer3D_COMPOUND_CID_197366.asnt\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: PASS (Text)\n",
      "  Encoding: PASS\n",
      "  Schema Compliance: PASS\n",
      "  Mandatory Fields: PASS\n",
      "\n",
      "File: Structure2D_COMPOUND_CID_197365.asnt\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: PASS (Text)\n",
      "  Encoding: PASS\n",
      "  Schema Compliance: PASS\n",
      "  Mandatory Fields: PASS\n",
      "\n",
      "File: assessment.asnt\n",
      "  Format Check: nan\n",
      "  CDISC Compliance: nan\n",
      "  Required Variables: nan\n",
      "  Data Integrity: nan\n",
      "  Structure Check: nan\n",
      "  Molecule Count: nan\n",
      "  Property Blocks: nan\n",
      "  Connectivity: nan\n",
      "  ASN.1 Structure: PASS (XML)\n",
      "  Encoding: PASS\n",
      "  Schema Compliance: PASS\n",
      "  Mandatory Fields: FAIL\n",
      "  Issues: Missing mandatory fields: ['StudyID', 'Reviewer', 'AssessmentDate']\n",
      "\n",
      "=== FILE INTEGRITY CHECKS ===\n",
      "\n",
      "File: lb.xpt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: ae.xpt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: dm.xpt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: compound.sdf\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: Structure2D_COMPOUND_CID_197365.sdf\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: Conformer3D_COMPOUND_CID_197366.sdf\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: Conformer3D_COMPOUND_CID_197366.asnt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: Structure2D_COMPOUND_CID_197365.asnt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "File: assessment.asnt\n",
      "  File Size: PASS\n",
      "  File Exists: PASS\n",
      "  Readable: PASS\n",
      "  Issues: []\n",
      "\n",
      "Validation report saved to: validation_report.txt\n",
      "Validation results saved to: validation_results.csv\n",
      "Integrity results saved to: integrity_results.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:20:11] Atom line too short: '   -0.0015    1.2095    0.0000 C' on line 5\n"
     ]
    }
   ],
   "source": [
    "# Run comprehensive validation checks based on regulatory requirements\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Collect all validation results\n",
    "validation_report = []\n",
    "\n",
    "# Validate XPT files\n",
    "xpt_files = file_extensions.get('.xpt', [])\n",
    "for file_path in xpt_files:\n",
    "    result = validate_xpt_file(file_path)\n",
    "    validation_report.append(result)\n",
    "\n",
    "# Validate SDF files\n",
    "sdf_files = file_extensions.get('.sdf', [])\n",
    "for file_path in sdf_files:\n",
    "    result = validate_sdf_file(file_path)\n",
    "    validation_report.append(result)\n",
    "\n",
    "# Validate ASNT files\n",
    "asnt_files = file_extensions.get('.asnt', [])\n",
    "for file_path in asnt_files:\n",
    "    result = validate_asnt_file(file_path)\n",
    "    validation_report.append(result)\n",
    "\n",
    "# Validate file integrity for all files\n",
    "all_target_files = xpt_files + sdf_files + asnt_files\n",
    "integrity_report = []\n",
    "for file_path in all_target_files:\n",
    "    result = validate_file_integrity(file_path)\n",
    "    integrity_report.append(result)\n",
    "\n",
    "# Create validation summary DataFrame\n",
    "validation_df = pd.DataFrame(validation_report)\n",
    "integrity_df = pd.DataFrame(integrity_report)\n",
    "\n",
    "# Display validation results\n",
    "print(\"=== REGULATORY VALIDATION REPORT ===\")\n",
    "print(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Total files validated: {len(validation_report)}\")\n",
    "print()\n",
    "\n",
    "# Summary statistics\n",
    "total_checks = len(validation_df) * (len(validation_df.columns) - 2)  # Exclude 'File' and 'Issues'\n",
    "pass_count = 0\n",
    "fail_count = 0\n",
    "warn_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for _, row in validation_df.iterrows():\n",
    "    for col in validation_df.columns:\n",
    "        if col not in ['File', 'Issues']:\n",
    "            status = str(row[col]).upper()\n",
    "            if 'PASS' in status:\n",
    "                pass_count += 1\n",
    "            elif 'FAIL' in status:\n",
    "                fail_count += 1\n",
    "            elif 'WARN' in status:\n",
    "                warn_count += 1\n",
    "            elif 'ERROR' in status:\n",
    "                error_count += 1\n",
    "\n",
    "print(f\"Validation Summary:\")\n",
    "print(f\"  PASS: {pass_count}\")\n",
    "print(f\"  FAIL: {fail_count}\")\n",
    "print(f\"  WARN: {warn_count}\")\n",
    "print(f\"  ERROR: {error_count}\")\n",
    "print(f\"  Overall Compliance: {'PASS' if fail_count == 0 and error_count == 0 else 'REVIEW REQUIRED'}\")\n",
    "print()\n",
    "\n",
    "# Display detailed validation results\n",
    "print(\"Detailed Validation Results:\")\n",
    "for _, row in validation_df.iterrows():\n",
    "    print(f\"\\nFile: {row['File']}\")\n",
    "    for col in validation_df.columns:\n",
    "        if col not in ['File', 'Issues']:\n",
    "            status = row[col]\n",
    "            print(f\"  {col}: {status}\")\n",
    "    if row['Issues']:\n",
    "        print(f\"  Issues: {', '.join(row['Issues'])}\")\n",
    "\n",
    "print(\"\\n=== FILE INTEGRITY CHECKS ===\")\n",
    "for _, row in integrity_df.iterrows():\n",
    "    print(f\"\\nFile: {row['File']}\")\n",
    "    for col in integrity_df.columns:\n",
    "        if col != 'File':\n",
    "            status = row[col]\n",
    "            print(f\"  {col}: {status}\")\n",
    "    if row['Issues']:\n",
    "        print(f\"  Issues: {', '.join(row['Issues'])}\")\n",
    "\n",
    "# Save validation report to file\n",
    "validation_report_filename = 'validation_report.txt'\n",
    "with open(validation_report_filename, 'w') as f:\n",
    "    f.write(\"=== REGULATORY VALIDATION REPORT ===\\n\")\n",
    "    f.write(f\"Report generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"Total files validated: {len(validation_report)}\\n\\n\")\n",
    "    f.write(f\"Validation Summary:\\n\")\n",
    "    f.write(f\"  PASS: {pass_count}\\n\")\n",
    "    f.write(f\"  FAIL: {fail_count}\\n\")\n",
    "    f.write(f\"  WARN: {warn_count}\\n\")\n",
    "    f.write(f\"  ERROR: {error_count}\\n\")\n",
    "    f.write(f\"  Overall Compliance: {'PASS' if fail_count == 0 and error_count == 0 else 'REVIEW REQUIRED'}\\n\\n\")\n",
    "    \n",
    "    f.write(\"Detailed Validation Results:\\n\")\n",
    "    for _, row in validation_df.iterrows():\n",
    "        f.write(f\"\\nFile: {row['File']}\\n\")\n",
    "        for col in validation_df.columns:\n",
    "            if col not in ['File', 'Issues']:\n",
    "                status = row[col]\n",
    "                f.write(f\"  {col}: {status}\\n\")\n",
    "        if row['Issues']:\n",
    "            f.write(f\"  Issues: {', '.join(row['Issues'])}\\n\")\n",
    "    \n",
    "    f.write(\"\\n=== FILE INTEGRITY CHECKS ===\\n\")\n",
    "    for _, row in integrity_df.iterrows():\n",
    "        f.write(f\"\\nFile: {row['File']}\\n\")\n",
    "        for col in integrity_df.columns:\n",
    "            if col != 'File':\n",
    "                status = row[col]\n",
    "                f.write(f\"  {col}: {status}\\n\")\n",
    "        if row['Issues']:\n",
    "            f.write(f\"  Issues: {', '.join(row['Issues'])}\\n\")\n",
    "\n",
    "print(f\"\\nValidation report saved to: {validation_report_filename}\")\n",
    "\n",
    "# Save validation data to CSV for further analysis\n",
    "validation_csv_filename = 'validation_results.csv'\n",
    "validation_df.to_csv(validation_csv_filename, index=False)\n",
    "integrity_df.to_csv('integrity_results.csv', index=False)\n",
    "print(f\"Validation results saved to: {validation_csv_filename}\")\n",
    "print(f\"Integrity results saved to: integrity_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced Comprehensive File Summary Table with Detailed Content Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[17:20:11] ERROR: Atom line too short: '   -0.0015    1.2095    0.0000 C' on line 5\n",
      "[17:20:11] ERROR: moving to the beginning of the next molecule\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File Name</th>\n",
       "      <th>Extension</th>\n",
       "      <th>File Path</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Columns</th>\n",
       "      <th>First 5 rows</th>\n",
       "      <th>Summary statistics</th>\n",
       "      <th>Number of molecules</th>\n",
       "      <th>First molecule</th>\n",
       "      <th>Molecular weight</th>\n",
       "      <th>Number of atoms</th>\n",
       "      <th>Number of bonds</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Number of records</th>\n",
       "      <th>XML Root</th>\n",
       "      <th>StudyID</th>\n",
       "      <th>Reviewer</th>\n",
       "      <th>AssessmentDate</th>\n",
       "      <th>Findings</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lb.xpt</td>\n",
       "      <td>.XPT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>['STUDYID', 'USUBJID', 'LBTEST', 'LBSTRESN', '...</td>\n",
       "      <td>STUDYID  USUBJID      LBTEST  LBSTRESN LBSTR...</td>\n",
       "      <td>LBSTRESN\\ncount   2.00000\\nmean   51.10...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ae.xpt</td>\n",
       "      <td>.XPT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td>(2, 5)</td>\n",
       "      <td>['STUDYID', 'USUBJID', 'AETERM', 'AESEV', 'AER...</td>\n",
       "      <td>STUDYID  USUBJID    AETERM     AESEV      AE...</td>\n",
       "      <td>STUDYID  USUBJID    AETERM AESEV    AER...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dm.xpt</td>\n",
       "      <td>.XPT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td>(2, 4)</td>\n",
       "      <td>['STUDYID', 'USUBJID', 'AGE', 'SEX']</td>\n",
       "      <td>STUDYID  USUBJID   AGE SEX\\n0  ABC123  SUBJ0...</td>\n",
       "      <td>AGE\\ncount   2.000000\\nmean   48....</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>compound.sdf</td>\n",
       "      <td>.SDF</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Structure2D_COMPOUND_CID_197365.sdf</td>\n",
       "      <td>.SDF</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>197365</td>\n",
       "      <td>699.99</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Conformer3D_COMPOUND_CID_197366.sdf</td>\n",
       "      <td>.SDF</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>197366</td>\n",
       "      <td>590.60</td>\n",
       "      <td>41</td>\n",
       "      <td>46</td>\n",
       "      <td>CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Conformer3D_COMPOUND_CID_197366.asnt</td>\n",
       "      <td>.ASNT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Structure2D_COMPOUND_CID_197365.asnt</td>\n",
       "      <td>.ASNT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>assessment.asnt</td>\n",
       "      <td>.ASNT</td>\n",
       "      <td>m5/53-clin-stud-reports/study1234/datasets/dat...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>AssessmentTemplate</td>\n",
       "      <td>STUDY1234</td>\n",
       "      <td>Dr. Smith</td>\n",
       "      <td>2025-11-05</td>\n",
       "      <td>\\n</td>\n",
       "      <td>Approved for next review phase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              File Name Extension  \\\n",
       "0                                lb.xpt      .XPT   \n",
       "1                                ae.xpt      .XPT   \n",
       "2                                dm.xpt      .XPT   \n",
       "3                          compound.sdf      .SDF   \n",
       "4   Structure2D_COMPOUND_CID_197365.sdf      .SDF   \n",
       "5   Conformer3D_COMPOUND_CID_197366.sdf      .SDF   \n",
       "6  Conformer3D_COMPOUND_CID_197366.asnt     .ASNT   \n",
       "7  Structure2D_COMPOUND_CID_197365.asnt     .ASNT   \n",
       "8                       assessment.asnt     .ASNT   \n",
       "\n",
       "                                           File Path   Shape  \\\n",
       "0  m5/53-clin-stud-reports/study1234/datasets/dat...  (2, 5)   \n",
       "1  m5/53-clin-stud-reports/study1234/datasets/dat...  (2, 5)   \n",
       "2  m5/53-clin-stud-reports/study1234/datasets/dat...  (2, 4)   \n",
       "3  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "4  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "5  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "6  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "7  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "8  m5/53-clin-stud-reports/study1234/datasets/dat...           \n",
       "\n",
       "                                             Columns  \\\n",
       "0  ['STUDYID', 'USUBJID', 'LBTEST', 'LBSTRESN', '...   \n",
       "1  ['STUDYID', 'USUBJID', 'AETERM', 'AESEV', 'AER...   \n",
       "2               ['STUDYID', 'USUBJID', 'AGE', 'SEX']   \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "\n",
       "                                        First 5 rows  \\\n",
       "0    STUDYID  USUBJID      LBTEST  LBSTRESN LBSTR...   \n",
       "1    STUDYID  USUBJID    AETERM     AESEV      AE...   \n",
       "2    STUDYID  USUBJID   AGE SEX\\n0  ABC123  SUBJ0...   \n",
       "3                                                      \n",
       "4                                                      \n",
       "5                                                      \n",
       "6                                                      \n",
       "7                                                      \n",
       "8                                                      \n",
       "\n",
       "                                  Summary statistics Number of molecules  \\\n",
       "0         LBSTRESN\\ncount   2.00000\\nmean   51.10...                       \n",
       "1         STUDYID  USUBJID    AETERM AESEV    AER...                       \n",
       "2               AGE\\ncount   2.000000\\nmean   48....                       \n",
       "3                                                                      0   \n",
       "4                                                                      1   \n",
       "5                                                                      1   \n",
       "6                                                                          \n",
       "7                                                                          \n",
       "8                                                                          \n",
       "\n",
       "  First molecule Molecular weight Number of atoms Number of bonds  \\\n",
       "0                                                                   \n",
       "1                                                                   \n",
       "2                                                                   \n",
       "3            N/A              N/A             N/A             N/A   \n",
       "4         197365           699.99              44              46   \n",
       "5         197366           590.60              41              46   \n",
       "6                                                                   \n",
       "7                                                                   \n",
       "8                                                                   \n",
       "\n",
       "                                              SMILES Number of records  \\\n",
       "0                                                                        \n",
       "1                                                                        \n",
       "2                                                                        \n",
       "3                                                N/A                     \n",
       "4  CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl...                     \n",
       "5  CN1CCN(c2ccc3nc(-c4ccc5nc(CCCc6ccc(N(CCCl)CCCl...                     \n",
       "6                                                                    0   \n",
       "7                                                                    0   \n",
       "8                                                                    1   \n",
       "\n",
       "             XML Root    StudyID   Reviewer AssessmentDate Findings  \\\n",
       "0                                                                     \n",
       "1                                                                     \n",
       "2                                                                     \n",
       "3                                                                     \n",
       "4                                                                     \n",
       "5                                                                     \n",
       "6                 N/A        N/A        N/A            N/A      N/A   \n",
       "7                 N/A        N/A        N/A            N/A      N/A   \n",
       "8  AssessmentTemplate  STUDY1234  Dr. Smith     2025-11-05   \\n       \n",
       "\n",
       "                   Recommendation  \n",
       "0                                  \n",
       "1                                  \n",
       "2                                  \n",
       "3                                  \n",
       "4                                  \n",
       "5                                  \n",
       "6                             N/A  \n",
       "7                             N/A  \n",
       "8  Approved for next review phase  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create enhanced summary table with detailed content columns\n",
    "import pandas as pd\n",
    "\n",
    "# Helper functions to extract detailed file information\n",
    "def analyze_sdf_file(file_path):\n",
    "    \"\"\"Analyze SDF file and return detailed information.\"\"\"\n",
    "    try:\n",
    "        from rdkit import Chem\n",
    "        from rdkit.Chem import Descriptors\n",
    "        \n",
    "        suppl = Chem.SDMolSupplier(str(file_path))\n",
    "        molecules = [mol for mol in suppl if mol is not None]\n",
    "        \n",
    "        if molecules:\n",
    "            mol = molecules[0]\n",
    "            return {\n",
    "                'Number of molecules': len(molecules),\n",
    "                'First molecule': mol.GetProp('_Name') if mol.HasProp('_Name') else 'Unnamed',\n",
    "                'Molecular weight': f\"{Descriptors.MolWt(mol):.2f}\",\n",
    "                'Number of atoms': mol.GetNumAtoms(),\n",
    "                'Number of bonds': mol.GetNumBonds(),\n",
    "                'SMILES': Chem.MolToSmiles(mol)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                'Number of molecules': 0,\n",
    "                'First molecule': 'N/A',\n",
    "                'Molecular weight': 'N/A',\n",
    "                'Number of atoms': 'N/A',\n",
    "                'Number of bonds': 'N/A',\n",
    "                'SMILES': 'N/A'\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Number of molecules': 'Error',\n",
    "            'First molecule': f'Error: {str(e)}',\n",
    "            'Molecular weight': 'Error',\n",
    "            'Number of atoms': 'Error',\n",
    "            'Number of bonds': 'Error',\n",
    "            'SMILES': 'Error'\n",
    "        }\n",
    "\n",
    "def analyze_xpt_file(file_path):\n",
    "    \"\"\"Analyze XPT file and return detailed information.\"\"\"\n",
    "    try:\n",
    "        import pyreadstat\n",
    "        \n",
    "        df, meta = pyreadstat.read_xport(str(file_path))\n",
    "        \n",
    "        # Get first 5 rows as formatted string\n",
    "        first_rows = df.head().to_string(index=True)\n",
    "        \n",
    "        # Get summary statistics\n",
    "        stats = df.describe().to_string()\n",
    "        \n",
    "        return {\n",
    "            'Shape': str(df.shape),\n",
    "            'Columns': str(list(df.columns)),\n",
    "            'First 5 rows': first_rows,\n",
    "            'Summary statistics': stats\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Shape': f'Error: {str(e)}',\n",
    "            'Columns': 'Error',\n",
    "            'First 5 rows': 'Error',\n",
    "            'Summary statistics': 'Error'\n",
    "        }\n",
    "\n",
    "def analyze_asnt_file(file_path):\n",
    "    \"\"\"Analyze ASNT file and return detailed information.\"\"\"\n",
    "    try:\n",
    "        from Bio import SeqIO\n",
    "        import xml.etree.ElementTree as ET\n",
    "        \n",
    "        # Check if it's XML\n",
    "        with open(file_path, 'r') as f:\n",
    "            first_line = f.readline()\n",
    "            \n",
    "        if first_line.startswith('<?xml'):\n",
    "            # It's XML, parse as XML\n",
    "            tree = ET.parse(str(file_path))\n",
    "            root = tree.getroot()\n",
    "            records = [root]\n",
    "        else:\n",
    "            # Try as ASN.1 sequence\n",
    "            records = list(SeqIO.parse(str(file_path), \"genbank\"))\n",
    "        \n",
    "        if records:\n",
    "            record = records[0]\n",
    "            if hasattr(record, 'id'):  # BioPython record\n",
    "                return {\n",
    "                    'Number of records': len(records),\n",
    "                    'XML Root': 'N/A (ASN.1 format)',\n",
    "                    'StudyID': 'N/A',\n",
    "                    'Reviewer': 'N/A',\n",
    "                    'AssessmentDate': 'N/A',\n",
    "                    'Findings': 'N/A',\n",
    "                    'Recommendation': 'N/A'\n",
    "                }\n",
    "            else:  # XML element\n",
    "                # Extract XML data\n",
    "                xml_data = {}\n",
    "                for child in record:\n",
    "                    xml_data[child.tag] = child.text or ''\n",
    "                \n",
    "                return {\n",
    "                    'Number of records': len(records),\n",
    "                    'XML Root': record.tag,\n",
    "                    'StudyID': xml_data.get('StudyID', ''),\n",
    "                    'Reviewer': xml_data.get('Reviewer', ''),\n",
    "                    'AssessmentDate': xml_data.get('AssessmentDate', ''),\n",
    "                    'Findings': xml_data.get('Findings', ''),\n",
    "                    'Recommendation': xml_data.get('Recommendation', '')\n",
    "                }\n",
    "        else:\n",
    "            return {\n",
    "                'Number of records': 0,\n",
    "                'XML Root': 'N/A',\n",
    "                'StudyID': 'N/A',\n",
    "                'Reviewer': 'N/A',\n",
    "                'AssessmentDate': 'N/A',\n",
    "                'Findings': 'N/A',\n",
    "                'Recommendation': 'N/A'\n",
    "            }\n",
    "    except Exception as e:\n",
    "        return {\n",
    "            'Number of records': f'Error: {str(e)}',\n",
    "            'XML Root': 'Error',\n",
    "            'StudyID': 'Error',\n",
    "            'Reviewer': 'Error',\n",
    "            'AssessmentDate': 'Error',\n",
    "            'Findings': 'Error',\n",
    "            'Recommendation': 'Error'\n",
    "        }\n",
    "\n",
    "# Filter for only the three file types\n",
    "target_extensions = ['.xpt', '.sdf', '.asnt']\n",
    "\n",
    "# Create summary data with detailed columns\n",
    "summary_data = []\n",
    "for ext in target_extensions:\n",
    "    if ext in file_extensions:\n",
    "        files = file_extensions[ext]\n",
    "        \n",
    "        for file_path in files:\n",
    "            file_name = file_path.name\n",
    "            \n",
    "            # Initialize row data\n",
    "            row = {\n",
    "                'File Name': file_name,\n",
    "                'Extension': ext.upper(),\n",
    "                'File Path': str(file_path)\n",
    "            }\n",
    "            \n",
    "            # Add file-specific detailed columns\n",
    "            if ext == '.sdf':\n",
    "                sdf_info = analyze_sdf_file(file_path)\n",
    "                row.update({\n",
    "                    'Number of molecules': sdf_info['Number of molecules'],\n",
    "                    'First molecule': sdf_info['First molecule'],\n",
    "                    'Molecular weight': sdf_info['Molecular weight'],\n",
    "                    'Number of atoms': sdf_info['Number of atoms'],\n",
    "                    'Number of bonds': sdf_info['Number of bonds'],\n",
    "                    'SMILES': sdf_info['SMILES']\n",
    "                })\n",
    "                # Add empty columns for other file types\n",
    "                row.update({\n",
    "                    'Shape': '',\n",
    "                    'Columns': '',\n",
    "                    'First 5 rows': '',\n",
    "                    'Summary statistics': '',\n",
    "                    'Number of records': '',\n",
    "                    'XML Root': '',\n",
    "                    'StudyID': '',\n",
    "                    'Reviewer': '',\n",
    "                    'AssessmentDate': '',\n",
    "                    'Findings': '',\n",
    "                    'Recommendation': ''\n",
    "                })\n",
    "            \n",
    "            elif ext == '.xpt':\n",
    "                xpt_info = analyze_xpt_file(file_path)\n",
    "                row.update({\n",
    "                    'Shape': xpt_info['Shape'],\n",
    "                    'Columns': xpt_info['Columns'],\n",
    "                    'First 5 rows': xpt_info['First 5 rows'],\n",
    "                    'Summary statistics': xpt_info['Summary statistics']\n",
    "                })\n",
    "                # Add empty columns for other file types\n",
    "                row.update({\n",
    "                    'Number of molecules': '',\n",
    "                    'First molecule': '',\n",
    "                    'Molecular weight': '',\n",
    "                    'Number of atoms': '',\n",
    "                    'Number of bonds': '',\n",
    "                    'SMILES': '',\n",
    "                    'Number of records': '',\n",
    "                    'XML Root': '',\n",
    "                    'StudyID': '',\n",
    "                    'Reviewer': '',\n",
    "                    'AssessmentDate': '',\n",
    "                    'Findings': '',\n",
    "                    'Recommendation': ''\n",
    "                })\n",
    "            \n",
    "            elif ext == '.asnt':\n",
    "                asnt_info = analyze_asnt_file(file_path)\n",
    "                row.update({\n",
    "                    'Number of records': asnt_info['Number of records'],\n",
    "                    'XML Root': asnt_info['XML Root'],\n",
    "                    'StudyID': asnt_info['StudyID'],\n",
    "                    'Reviewer': asnt_info['Reviewer'],\n",
    "                    'AssessmentDate': asnt_info['AssessmentDate'],\n",
    "                    'Findings': asnt_info['Findings'],\n",
    "                    'Recommendation': asnt_info['Recommendation']\n",
    "                })\n",
    "                # Add empty columns for other file types\n",
    "                row.update({\n",
    "                    'Number of molecules': '',\n",
    "                    'First molecule': '',\n",
    "                    'Molecular weight': '',\n",
    "                    'Number of atoms': '',\n",
    "                    'Number of bonds': '',\n",
    "                    'SMILES': '',\n",
    "                    'Shape': '',\n",
    "                    'Columns': '',\n",
    "                    'First 5 rows': '',\n",
    "                    'Summary statistics': ''\n",
    "                })\n",
    "            \n",
    "            summary_data.append(row)\n",
    "\n",
    "# Create DataFrame and display\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Summary Table to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary table saved to SD_Study-Data-files.csv\n",
      "CSV file contains 9 rows and 20 columns\n",
      "Columns: ['File Name', 'Extension', 'File Path', 'Shape', 'Columns', 'First 5 rows', 'Summary statistics', 'Number of molecules', 'First molecule', 'Molecular weight', 'Number of atoms', 'Number of bonds', 'SMILES', 'Number of records', 'XML Root', 'StudyID', 'Reviewer', 'AssessmentDate', 'Findings', 'Recommendation']\n"
     ]
    }
   ],
   "source": [
    "# Save the summary table to CSV\n",
    "csv_filename = 'SD_Study-Data-files.csv'\n",
    "summary_df.to_csv(csv_filename, index=False)\n",
    "print(f\"Summary table saved to {csv_filename}\")\n",
    "print(f\"CSV file contains {len(summary_df)} rows and {len(summary_df.columns)} columns\")\n",
    "print(f\"Columns: {list(summary_df.columns)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
